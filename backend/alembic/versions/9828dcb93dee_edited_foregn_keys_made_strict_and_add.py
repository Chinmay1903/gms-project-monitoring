"""edited foregn keys made strict and add foregn key in task_monitor

Revision ID: 9828dcb93dee
Revises: 18639a434352
Create Date: 2025-11-11 12:26:35.960430

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy import text


# revision identifiers, used by Alembic.
revision: str = '9828dcb93dee'
down_revision: Union[str, Sequence[str], None] = '18639a434352'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None

def _drop_fk_by_col(table: str, col: str, conn):
    """
    Drop all FK constraints in `table` that reference the given column `col`.
    Works on PostgreSQL.
    """
    q = text("""
        SELECT tc.constraint_name
        FROM information_schema.table_constraints AS tc
        JOIN information_schema.key_column_usage AS kcu
          ON tc.constraint_name = kcu.constraint_name
         AND tc.table_schema = kcu.table_schema
        WHERE tc.constraint_type = 'FOREIGN KEY'
          AND tc.table_name = :table
          AND kcu.column_name = :col
    """)
    for row in conn.execute(q, {"table": table, "col": col}).fetchall():
        op.drop_constraint(row[0], table_name=table, type_="foreignkey")


def _drop_fk_by_table(table: str, conn):
    """
    Drop all FK constraints for a table (used when we do not know the names).
    """
    q = text("""
        SELECT tc.constraint_name
        FROM information_schema.table_constraints AS tc
        WHERE tc.constraint_type = 'FOREIGN KEY'
          AND tc.table_name = :table
    """)
    for row in conn.execute(q, {"table": table}).fetchall():
        op.drop_constraint(row[0], table_name=table, type_="foreignkey")


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    conn = op.get_bind()

    # 1) employees.role → roles.role_id (SET NULL -> RESTRICT)
    #    Drop existing FK(s) on employees(role), recreate with RESTRICT
    _drop_fk_by_col("employees", "role", conn)
    op.create_foreign_key(
        "fk_employees_role_restrict",
        source_table="employees",
        referent_table="roles",
        local_cols=["role"],
        remote_cols=["role_id"],
        ondelete="RESTRICT",  # explicit (DEFAULT also restricts deletes)
        onupdate=None,
    )

    # 2) project_staffing: change FKs CASCADE -> RESTRICT
    #    Drop all FKs (safer), recreate 2 with RESTRICT
    _drop_fk_by_table("project_staffing", conn)

    op.create_foreign_key(
        "fk_project_staffing_project_restrict",
        source_table="project_staffing",
        referent_table="projects",
        local_cols=["project_id"],
        remote_cols=["project_id"],
        ondelete="RESTRICT",
    )
    op.create_foreign_key(
        "fk_project_staffing_employee_restrict",
        source_table="project_staffing",
        referent_table="employees",
        local_cols=["employees_id"],
        remote_cols=["employees_id"],
        ondelete="RESTRICT",
    )

    # 3) task_monitors refactor:
    #    - add project_staffing_id (nullable for now)
    #    - FK to project_staffing (RESTRICT)
    op.add_column(
        "task_monitors",
        sa.Column("project_staffing_id", sa.BigInteger(), nullable=True),
    )
    op.create_foreign_key(
        "fk_task_monitors_project_staffing_restrict",
        source_table="task_monitors",
        referent_table="project_staffing",
        local_cols=["project_staffing_id"],
        remote_cols=["id"],
        ondelete="RESTRICT",
    )

    # 3a) Backfill project_staffing_id from old (project_id, employees_id)
    #     NOTE: This relies on existing task_monitors columns employees_id + project_id.
    #     If there are multiple staffing rows per (project_id, employees_id), this assigns
    #     the matching row arbitrarily (usually only one is expected).
    conn.execute(text("""
        UPDATE task_monitors tm
        SET project_staffing_id = ps.id
        FROM project_staffing ps
        WHERE ps.project_id = tm.project_id
          AND ps.employees_id = tm.employees_id
    """))

    # 3b) Enforce NOT NULL after backfill
    #     If any rows remain NULL, the next line will fail — fix data first if needed.
    op.alter_column("task_monitors", "project_staffing_id", nullable=False)

    # 3c) (Optional but recommended) add a uniqueness/index for (project_staffing_id, task_date)
    #     to prevent duplicates per trainer+project per day
    op.create_index(
        "ix_task_monitors_psid_date",
        "task_monitors",
        ["project_staffing_id", "task_date"],
        unique=False,
    )

    # 3d) Drop old FKs and columns from task_monitors
    _drop_fk_by_col("task_monitors", "employees_id", conn)
    _drop_fk_by_col("task_monitors", "project_id", conn)
    with op.batch_alter_table("task_monitors") as batch:
        batch.drop_column("employees_id")
        batch.drop_column("project_id")
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    conn = op.get_bind()

    # 1) task_monitors: reintroduce employees_id + project_id, backfill, restore old FKs (CASCADE)

    # 1a) add columns (nullable first)
    with op.batch_alter_table("task_monitors") as batch:
        batch.add_column(sa.Column("employees_id", sa.String(36), nullable=True))
        batch.add_column(sa.Column("project_id", sa.Integer(), nullable=True))

    # 1b) backfill from project_staffing_id
    conn.execute(text("""
        UPDATE task_monitors tm
        SET employees_id = ps.employees_id,
            project_id   = ps.project_id
        FROM project_staffing ps
        WHERE ps.id = tm.project_staffing_id
    """))

    # 1c) enforce NOT NULL (if data is consistent)
    op.alter_column("task_monitors", "employees_id", nullable=False)
    op.alter_column("task_monitors", "project_id",   nullable=False)

    # 1d) drop new FK/index, then re-create old FKs with CASCADE
    op.drop_constraint(
        "fk_task_monitors_project_staffing_restrict",
        table_name="task_monitors",
        type_="foreignkey",
    )
    op.drop_index("ix_task_monitors_psid_date", table_name="task_monitors")

    # remove project_staffing_id
    with op.batch_alter_table("task_monitors") as batch:
        batch.drop_column("project_staffing_id")

    # restore previous FKs (CASCADE)
    op.create_foreign_key(
        "fk_task_monitors_employees_cascade",
        source_table="task_monitors",
        referent_table="employees",
        local_cols=["employees_id"],
        remote_cols=["employees_id"],
        ondelete="CASCADE",
    )
    op.create_foreign_key(
        "fk_task_monitors_projects_cascade",
        source_table="task_monitors",
        referent_table="projects",
        local_cols=["project_id"],
        remote_cols=["project_id"],
        ondelete="CASCADE",
    )

    # 2) project_staffing: switch RESTRICT back to CASCADE
    _drop_fk_by_table("project_staffing", conn)
    op.create_foreign_key(
        "fk_project_staffing_project_cascade",
        source_table="project_staffing",
        referent_table="projects",
        local_cols=["project_id"],
        remote_cols=["project_id"],
        ondelete="CASCADE",
    )
    op.create_foreign_key(
        "fk_project_staffing_employee_cascade",
        source_table="project_staffing",
        referent_table="employees",
        local_cols=["employees_id"],
        remote_cols=["employees_id"],
        ondelete="CASCADE",
    )

    # 3) employees.role: RESTRICT -> SET NULL (original)
    _drop_fk_by_col("employees", "role", conn)
    op.create_foreign_key(
        "fk_employees_role_setnull",
        source_table="employees",
        referent_table="roles",
        local_cols=["role"],
        remote_cols=["role_id"],
        ondelete="SET NULL",
    )
    # ### end Alembic commands ###
